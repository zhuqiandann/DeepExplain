{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## DeepExplain - Tensorflow example\n",
    "### MNIST with a 2-layers MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\xiaoke\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting E:\\WithWeng\\DeepExplain\\data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\xiaoke\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting E:\\WithWeng\\DeepExplain\\data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\xiaoke\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting E:\\WithWeng\\DeepExplain\\data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting E:\\WithWeng\\DeepExplain\\data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\xiaoke\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "# Download and import MNIST data\n",
    "# tmp_dir = tempfile.gettempdir()\n",
    "mnist = input_data.read_data_sets(\"E:\\WithWeng\\DeepExplain\\data\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.005\n",
    "num_steps = 2000\n",
    "batch_size = 128\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1], mean=0.0, stddev=0.05)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], mean=0.0, stddev=0.05)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes], mean=0.0, stddev=0.05))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.zeros([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.zeros([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.zeros([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-f9332d3b7ed2>:14: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "Step 1, Minibatch Loss= 2.9643, Training Accuracy= 0.180\n",
      "Step 100, Minibatch Loss= 0.2348, Training Accuracy= 0.914\n",
      "Step 200, Minibatch Loss= 0.2443, Training Accuracy= 0.914\n",
      "Step 300, Minibatch Loss= 0.2197, Training Accuracy= 0.945\n",
      "Step 400, Minibatch Loss= 0.1266, Training Accuracy= 0.953\n",
      "Step 500, Minibatch Loss= 0.1614, Training Accuracy= 0.945\n",
      "Step 600, Minibatch Loss= 0.1393, Training Accuracy= 0.953\n",
      "Step 700, Minibatch Loss= 0.0669, Training Accuracy= 0.984\n",
      "Step 800, Minibatch Loss= 0.1668, Training Accuracy= 0.969\n",
      "Step 900, Minibatch Loss= 0.1020, Training Accuracy= 0.953\n",
      "Step 1000, Minibatch Loss= 0.1254, Training Accuracy= 0.961\n",
      "Step 1100, Minibatch Loss= 0.1278, Training Accuracy= 0.961\n",
      "Step 1200, Minibatch Loss= 0.1215, Training Accuracy= 0.945\n",
      "Step 1300, Minibatch Loss= 0.0331, Training Accuracy= 0.992\n",
      "Step 1400, Minibatch Loss= 0.0468, Training Accuracy= 0.984\n",
      "Step 1500, Minibatch Loss= 0.0268, Training Accuracy= 1.000\n",
      "Step 1600, Minibatch Loss= 0.1258, Training Accuracy= 0.969\n",
      "Step 1700, Minibatch Loss= 0.1279, Training Accuracy= 0.961\n",
      "Step 1800, Minibatch Loss= 0.0845, Training Accuracy= 0.977\n",
      "Step 1900, Minibatch Loss= 0.0984, Training Accuracy= 0.984\n",
      "Step 2000, Minibatch Loss= 0.0703, Training Accuracy= 0.992\n",
      "Done\n",
      "Test accuracy: 0.9585\n"
     ]
    }
   ],
   "source": [
    "# Create and train model\n",
    "def model(x, act=tf.nn.relu):  # < different activation functions lead to different explanations\n",
    "    layer_1 = act(tf.add(tf.matmul(x, weights['h1']), biases['b1']))\n",
    "    layer_2 = act(tf.add(tf.matmul(layer_1, weights['h2']), biases['b2']))\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# Construct model\n",
    "logits = model(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Train\n",
    "def input_transform (x): \n",
    "    return (x - 0.5) *  2\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(1, num_steps+1):\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    batch_x = input_transform(batch_x)\n",
    "    # Run optimization op (backprop)\n",
    "    sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "    if step % 100 == 0 or step == 1:\n",
    "        # Calculate batch loss and accuracy\n",
    "        loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                             Y: batch_y})\n",
    "        print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "              \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "              \"{:.3f}\".format(acc))\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "# Calculate accuracy for MNIST test images\n",
    "test_x = input_transform(mnist.test.images)\n",
    "test_y = mnist.test.labels\n",
    "\n",
    "print(\"Test accuracy:\",\n",
    "    sess.run(accuracy, feed_dict={X: test_x, Y: test_y}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use DeepExplain to find attributions for each input pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Done\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Line2D' object has no property 'cmap'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-7c9ad9149746>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[0mn_cols\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mattributions\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[0mfig\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msubplots\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mncols\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn_cols\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfigsize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mn_cols\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 37\u001B[1;33m \u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mxi\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m28\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m28\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcmap\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'Greys'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxes\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_title\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Original'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     38\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod_name\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msorted\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mattributions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m     \u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mattributions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mmethod_name\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m28\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m28\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxi\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mxi\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m28\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m28\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxes\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_title\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmethod_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\xiaoke\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\matplotlib\\pyplot.py\u001B[0m in \u001B[0;36mplot\u001B[1;34m(scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2840\u001B[0m     return gca().plot(\n\u001B[0;32m   2841\u001B[0m         \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscalex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mscalex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscaley\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mscaley\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2842\u001B[1;33m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001B[0m\u001B[0;32m   2843\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2844\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\xiaoke\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001B[0m in \u001B[0;36mplot\u001B[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1741\u001B[0m         \"\"\"\n\u001B[0;32m   1742\u001B[0m         \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcbook\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnormalize_kwargs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmlines\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLine2D\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1743\u001B[1;33m         \u001B[0mlines\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_lines\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1744\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mline\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mlines\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1745\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_line\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mline\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\xiaoke\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m    271\u001B[0m                 \u001B[0mthis\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    272\u001B[0m                 \u001B[0margs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 273\u001B[1;33m             \u001B[1;32myield\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_plot_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    274\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    275\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_next_color\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\xiaoke\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001B[0m in \u001B[0;36m_plot_args\u001B[1;34m(self, tup, kwargs)\u001B[0m\n\u001B[0;32m    417\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"x has {ncx} columns but y has {ncy} columns\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    418\u001B[0m         return [func(x[:, j % ncx], y[:, j % ncy], kw, kwargs)\n\u001B[1;32m--> 419\u001B[1;33m                 for j in range(max(ncx, ncy))]\n\u001B[0m\u001B[0;32m    420\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    421\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\xiaoke\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    417\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"x has {ncx} columns but y has {ncy} columns\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    418\u001B[0m         return [func(x[:, j % ncx], y[:, j % ncy], kw, kwargs)\n\u001B[1;32m--> 419\u001B[1;33m                 for j in range(max(ncx, ncy))]\n\u001B[0m\u001B[0;32m    420\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    421\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\xiaoke\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001B[0m in \u001B[0;36m_makeline\u001B[1;34m(self, x, y, kw, kwargs)\u001B[0m\n\u001B[0;32m    310\u001B[0m         \u001B[0mdefault_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getdefaults\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    311\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_setdefaults\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdefault_dict\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 312\u001B[1;33m         \u001B[0mseg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmlines\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLine2D\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mseg\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\xiaoke\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\matplotlib\\lines.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, xdata, ydata, linewidth, linestyle, color, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001B[0m\n\u001B[0;32m    388\u001B[0m         \u001B[1;31m# update kwargs before updating data to give the caller a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    389\u001B[0m         \u001B[1;31m# chance to init axes (and hence unit support)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 390\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    391\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpickradius\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpickradius\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    392\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mind_offset\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\xiaoke\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\matplotlib\\artist.py\u001B[0m in \u001B[0;36mupdate\u001B[1;34m(self, props)\u001B[0m\n\u001B[0;32m    994\u001B[0m                     \u001B[0mfunc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34mf\"set_{k}\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    995\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mcallable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 996\u001B[1;33m                         raise AttributeError(f\"{type(self).__name__!r} object \"\n\u001B[0m\u001B[0;32m    997\u001B[0m                                              f\"has no property {k!r}\")\n\u001B[0;32m    998\u001B[0m                     \u001B[0mret\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Line2D' object has no property 'cmap'"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1728x216 with 8 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import DeepExplain\n",
    "from deepexplain.tensorflow import DeepExplain\n",
    "%time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import plot\n",
    "%matplotlib inline\n",
    "\n",
    "# Define the input to be tested\n",
    "test_idx = 13\n",
    "xi = test_x[[test_idx]]\n",
    "yi = test_y[test_idx] \n",
    "\n",
    "# Create a DeepExplain context. \n",
    "# IMPORTANT: the network must be created within this context.\n",
    "# In this example we have trained the network before, so we call `model(X)` to \n",
    "# recreate the network graph using the same weights that have been already trained.\n",
    "with DeepExplain(session=sess) as de:\n",
    "    logits = model(X)\n",
    "    # We run `explain()` several time to compare different attribution methods\n",
    "    attributions = {\n",
    "        # Gradient-based\n",
    "        'Saliency maps':        de.explain('saliency', logits * yi, X, xi),\n",
    "        'Gradient * Input':     de.explain('grad*input', logits * yi, X, xi),\n",
    "        'Integrated Gradients': de.explain('intgrad', logits * yi, X, xi),\n",
    "        'Epsilon-LRP':          de.explain('elrp', logits * yi, X, xi),\n",
    "        'DeepLIFT (Rescale)':   de.explain('deeplift', logits * yi, X, xi),\n",
    "        #Perturbation-based\n",
    "        '_Occlusion [1x1]':      de.explain('occlusion', logits * yi, X, xi),\n",
    "        '_Occlusion [3x3]':      de.explain('occlusion', logits * yi, X, xi, window_shape=(3,))\n",
    "    }\n",
    "    print ('Done')\n",
    "\n",
    "# Plot attributions\n",
    "n_cols = len(attributions) + 1\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_cols, figsize=(3*n_cols, 3))\n",
    "plot(xi.reshape(28, 28), cmap='Greys', axis=axes[0]).set_title('Original')\n",
    "for i, method_name in enumerate(sorted(attributions.keys())):\n",
    "    plot(attributions[method_name].reshape(28,28), xi = xi.reshape(28, 28), axis=axes[1+i]).set_title(method_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}